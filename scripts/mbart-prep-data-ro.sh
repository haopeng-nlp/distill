root=/gscratch/ark/ivyg/fasttext-debias
langs=ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_lT,lv_lV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_lK,tr_TR,vi_VN,zh_CN

lang_pair=ro-en

if [[ $lang_pair == en-ro ]]; then
    src=en_XX
    tgt=ro_RO
    model_dir=$root/models/mbart-enro
    gold_dir=$root/distill/mbart/wmt_en_ro
elif [[ $lang_pair == ro-en ]]; then
    src=ro_RO
    tgt=en_XX
    model_dir=$root/models/mbart-roen
    gold_dir=$root/distill/mbart/wmt_en_ro
else
    echo "invalid lang_pair"
    exit
fi

bpe_model=$root/models/mbart.cc25.v2/sentence.bpe.model
DICT=$root/models/mbart.cc25.v2/dict.txt

spm_encode=$root/distill/scripts/spm_encode.py
spm_decode=$root/distill/scripts/spm_decode.py

REPLACE_UNICODE_PUNCT=$root/mosesdecoder/scripts/tokenizer/replace-unicode-punctuation.perl
NORM_PUNC=$root/mosesdecoder/scripts/tokenizer/normalize-punctuation.perl
REM_NON_PRINT_CHAR=$root/mosesdecoder/scripts/tokenizer/remove-non-printing-char.perl
REMOVE_DIACRITICS=$root/wmt16-scripts/preprocess/remove-diacritics.py
NORMALIZE_ROMANIAN=$root/wmt16-scripts/preprocess/normalise-romanian.py
TOKENIZER=$root/mosesdecoder/scripts/tokenizer/tokenizer.perl

noise=tdrop0.2
echo "noise=$noise"

seed=1
echo "seed=$seed"

retain_dropout=true
echo "retain_dropout=$retain_dropout"

read -n 1 -p "verify config (y/n) " ans
echo ""
if [[ $ans != y ]]; then
    exit
fi

data=$root/distill/mbart/data/$lang_pair
data_bin=$root/distill/mbart/data-bin/$lang_pair
DATA=$root/distill/mbart/data/$noise/$lang_pair
DATA_BIN=$root/distill/mbart/data-bin/$noise/$lang_pair

mkdir -p $data
mkdir -p $data_bin
mkdir -p $DATA
mkdir -p $DATA_BIN

### plain text to spm

# for split in train valid test; do
#     python $spm_encode --model=$bpe_model < $gold_dir/$split.$src > $data/$split.spm.$src
#     python $spm_encode --model=$bpe_model < $gold_dir/$split.$tgt > $data/$split.spm.$tgt
# done

### spm to binary

fairseq-preprocess \
    --source-lang $src \
    --target-lang $tgt \
    --srcdict $DICT \
    --tgtdict $DICT \
    --trainpref $data/train.spm \
    --validpref $data/valid.spm \
    --testpref $data/test.spm \
    --destdir $data_bin \
    --workers 70

### binary to plain text (generated by teacher with dropout)

if [ $noise == gold ]; then
    echo gold

    for lang in $src $tgt; do
        outfile=$DATA/train.$lang_pair.src
        if [ $lang == $tgt ]; then
            outfile=$DATA/train.$lang_pair.sys
        fi
        cat $gold_dir/train.$lang \
        | $REM_NON_PRINT_CHAR \
        | $NORM_PUNC -l ro \
        | $REPLACE_UNICODE_PUNCT \
        | $NORMALIZE_ROMANIAN \
        > $outfile
    done
else

for split in train; do
    dest=$DATA/$split

    model_pt=model.pt
    if [[ $noise == tdrop0.1 ]]; then
        model_pt=model.tdrop0.1.pt
    fi
    if [[ $noise == tdrop0.2 ]]; then
        model_pt=model.tdrop0.2.pt
    fi

    cmd="fairseq-generate $data_bin --path $model_dir/$model_pt --task translation_from_pretrained_bart --gen-subset $split --max-tokens 1000 -s $src -t $tgt --batch-size 128 --langs $langs --seed $seed"
    if $retain_dropout; then
        cmd="$cmd --retain-dropout"
    fi
    echo $cmd
    nohup $cmd > $dest.$lang_pair.out

    cat $dest.$lang_pair.out | grep -P "^S" | cut -f 2- | sed 's/\['$src'\]//g' > $dest.$lang_pair.src.temp
    cat $dest.$lang_pair.out | grep -P "^H" | cut -f 3- | sed 's/\['$tgt'\]//g' > $dest.$lang_pair.sys.temp

    for file in $dest.$lang_pair.src $dest.$lang_pair.sys; do
        $spm_decode --model=$bpe_model --input=$file.temp \
        | $REM_NON_PRINT_CHAR \
        | $NORM_PUNC -l ro \
        | $REPLACE_UNICODE_PUNCT \
        | $NORMALIZE_ROMANIAN \
        > $file
    done
done

fi

### plain text to bpe

# # clean valid/test
# for split in valid test; do
#     for lang in $src $tgt; do
#         cat $gold_dir/$split.$lang \
#         | $REM_NON_PRINT_CHAR \
#         | $NORM_PUNC -l ro \
#         | $REPLACE_UNICODE_PUNCT \
#         | $NORMALIZE_ROMANIAN \
#         > $gold_dir/$split.$lang.clean
#     done
# done

###

echo "encoding with $bpe_model"
python $spm_encode --model=$bpe_model < $DATA/train.$lang_pair.src > $DATA/train.spm.$lang_pair.$src
python $spm_encode --model=$bpe_model < $DATA/train.$lang_pair.sys > $DATA/train.spm.$lang_pair.$tgt

for split in valid test; do
    python $spm_encode --model=$bpe_model < $gold_dir/$split.$src.clean > $DATA/$split.spm.$lang_pair.$src
    python $spm_encode --model=$bpe_model < $gold_dir/$split.$tgt.clean > $DATA/$split.spm.$lang_pair.$tgt
done

### bpe to binary

echo "*.spm"
trainpref=train.spm.$lang_pair
validpref=valid.spm.$lang_pair
testpref=test.spm.$lang_pair
destdir=$DATA_BIN/spm
dictdir=$root/distill/mbart/data-bin/gold/$lang_pair/spm

echo "creating $destdir"
mkdir -p $destdir
rm $destdir/dict.* $destdir/preprocess.log

if [ $noise == gold ]; then
    echo "new dicts"
    fairseq-preprocess \
        --joined-dictionary \
        --source-lang $src \
        --target-lang $tgt \
        --trainpref $DATA/$trainpref \
        --validpref $DATA/$validpref \
        --testpref  $DATA/$testpref \
        --destdir $destdir \
        --workers 70
else
    echo "existing dicts"
    fairseq-preprocess \
        --srcdict $dictdir/dict.$src.txt \
        --tgtdict $dictdir/dict.$tgt.txt \
        --source-lang $src \
        --target-lang $tgt \
        --trainpref $DATA/$trainpref \
        --validpref $DATA/$validpref \
        --testpref  $DATA/$testpref \
        --destdir $destdir \
        --workers 70
fi
